<h1 align="center">STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models </h1>

<p align="center">
  <a><img 
     src="https://img.shields.io/badge/Qwen-Applications-4433FF?style=for-the-badge&logo=data:image/png;base64,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" 
     alt="Github"></a> 
  <a href='https://arxiv.org/abs/2602.03022'><img src='https://img.shields.io/badge/Paper-arXiv-red?style=for-the-badge&logo=arxiv' alt='arXiv PDF'></a>
  <a href='https://huggingface.co/star-lab'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Models-0984e3?style=for-the-badge'></a>
  <a href='https://huggingface.co/star-lab'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Datasets-00b894?style=for-the-badge'></a>
  <a href="https://opensource.org/licenses/Apache-2.0"><img src="https://img.shields.io/badge/License-Apache%202.0-green.svg?style=for-the-badge" alt="License"></a>
</p>

<p align="center">
  <i><b> <img src="https://img.alicdn.com/imgextra/i2/O1CN01FPcQDy1WTPjPX6IH9_!!6000000002789-2-tps-96-96.png" width="16px"  style="vertical-align: middle;"> Algorithm Platform Team, AI Hardware Division, Alibaba</b></i>
</p>

This repository contains the code and instructions necessary to reproduce the experiments presented in the paper: **"STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models"**, accepted to ICLR 2026.

**STAR (Similarity-guided Teacher-Assisted Refinement)** is a novel holistic framework designed to effectively transfer the function calling capabilities of large language models (LLMs) to super-tiny, cost-efficient models. Our STAR training curriculum involves the two processes:
1.  **Constrained Knowledge Distillation (CKD):** The selected teacher's knowledge is transferred to a super-tiny student model (e.g., **0.6B**) using our novel **Constrained Knowledge Distillation (CKD)** objective, which ensures training stability and preserves exploratory capacity.
2.  **Similarity-guided Reinforcement Learning (Sim-RL):** The distilled student model is polished with **Sim-RL** to enhance its generalization capability and optimize its performance on complex problems.




# üî• News

- **[2025.02.04]** We released the STAR codebase, including implementations for CKD and Sim-RL.
- **[2025.02.04]** Our paper is now available on arXiv: [2602.03022](https://arxiv.org/abs/2602.03022).
- **[2026.01.26]** Our paper has been accepted to ICLR 2026!


# üí° Main Results

Our STAR models establish new state-of-the-art performance in their size classes. The STAR framework significantly closes the performance gap with much larger models.

<p align="center">
  <img src="assets/main_results_table.png" alt="Main Results Table">
</p>

# üõ†Ô∏è Installation

We rely on [uv](https://docs.astral.sh/uv/getting-started/installation/) for Python environment management and [OpenRLHF](https://github.com/OpenRLHF/OpenRLHF) for our RL training framework.

1.  **Create Python Environment**

    ```bash
    # Create a virtual environment using uv
    uv venv --seed --python 3.12 ./train-env

    # Install dependencies
    uv pip sync -p ./train-env/bin/python ./requirements_uv.txt
    
    source ./train-env/bin/activate
    ```

2.  **Install Patched OpenRLHF**

    ```bash
    # Clone the specific commit of OpenRLHF
    git clone https://github.com/OpenRLHF/OpenRLHF.git
    cd OpenRLHF
    git checkout c1fc63a9f7e1837577a76b0c688809b3c0bdc644

    # Apply the patch for CKD functionality
    git apply ../0001-add-ckd.patch
    cd ..
    ```

# üéØ Quick Start

## Model Preparation

Download the base models from Hugging Face. We use the Qwen-8B model as the teacher and smaller models as students.
```bash
# Teacher Model
huggingface-cli download star-lab/Teacher-8B --local-dir models/Teacher-8B

# Student Models (e.g., 0.6B)
huggingface-cli download Qwen/Qwen3-0.6B --local-dir models/Qwen3-0.6B
```
                
## Data Preparation

Both CKD and SimRL require datasets in `jsonlines` format, where each line is a JSON object with two fields:
- `inputs`: The prompt formatted with the Qwen chat template.
- `outputs`: The response formatted with the Qwen chat template.

We recommend organizing your data into a structured format first (e.g., using the `messages` API format) and then converting it.

**Example structured format:**
```json
{
    "messages": [
        {"role": "system", "content": "..."},
        {"role": "user", "content": "..."},
        {"role": "assistant", "content": "...", "tool_calls": [...], "reasoning_content": "..."},
        {"role": "tool", "content": "..."},
    ],
    "tools": [
        {"name": "...", "description": "...", "parameters": ...},
    ]
}
```

The example_messages.jsonl file is provided as an example, containing 1024 random samples from the xlam50k dataset. Based on this structured data, the training data for CKD can be generated using the `teacher_rollout.py` script, while the training data for Sim-RL can be generated using the `messages_to_trainset.py` script:

CKD data:
```bash
python teacher_rollout.py --input=example_messages.jsonl --output=kd_messages.jsonl --model-path ./models/Teacher-8B --rollout-n 8 --dp-size 8 

python messages_to_trainset.py --input=kd_messages.jsonl --output=kd_data.jsonl --tokenizer-path=./models/Teacher-8B --add-reasoning-content
```

SimRL data:
```bash
python messages_to_trainset.py --input=example_messages.jsonl --output=rl_data.jsonl --tokenizer-path=./models/Teacher-8B
```

## Training: The STAR Curriculum

Before starting, prepare the environment for a training run:
```bash
export PYTHONPATH=$PWD/OpenRLHF
ray start --head --node-ip-address 0.0.0.0 --num-gpus 8 --disable-usage-stats
```

### Phase 1: Constrained Knowledge Distillation (CKD)

First, distill knowledge from the teacher model to the student using CKD. This step requires training data generated by the teacher model. We provide `teacher_rollout.py` as a reference for generating these samples.

After preparing your models and data, edit the paths in `scripts/train_ckd.sh` and run it:
```bash
bash scripts/train_ckd.sh
```
The distilled student model will be saved to the path specified in the script (e.g., `checkpoints/student-0.6b-ckd`).

### Phase 2: Similarity-guided Reinforcement Learning (Sim-RL)

Next, refine the CKD-distilled student model using Sim-RL to further boost its capabilities. While Sim-RL can be applied to any base model, it is most effective when used on a model already trained with CKD.

Update the model and data paths in `scripts/train_sim_rl.sh` and run the script:
```bash
bash scripts/train_sim_rl.sh
```
The final `STAR-0.6B` model will be saved to the path specified in the script (e.g., `checkpoints/star-0.6b`).

# üôèüèª Acknowledgements

This project is built upon the [OpenRLHF](https://github.com/OpenRLHF/OpenRLHF) framework. We thank the original authors for their significant open-source contributions.

# ‚≠êÔ∏è Citation

If you find this work useful, please kindly cite our paper:
```bibtex
@misc{ni2026starsimilarityguidedteacherassistedrefinement,
      title={STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models}, 
      author={Jiliang Ni and Jiachen Pu and Zhongyi Yang and Jingfeng Luo and Conggang Hu},
      year={2026},
      eprint={2602.03022},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2602.03022}, 
}
```
